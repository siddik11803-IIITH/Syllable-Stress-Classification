{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MpXLJZYu1_4j"
   },
   "source": [
    "# 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "2ERHkbgy1ulT"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zjomfTdt18o5"
   },
   "source": [
    "# 2. Utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7dt9H5Nf2vJ-"
   },
   "source": [
    "## 2.1 Metric Monitor\n",
    "Keeps track of average over values added to its instance. Useful to track accuracy over batches and epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "xnyphpqb10fG"
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "class MetricMonitor:\n",
    "    def __init__(self, float_precision=4):\n",
    "        self.float_precision = float_precision\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.metrics = defaultdict(lambda: {\"val\": 0, \"count\": 0, \"avg\": 0})\n",
    "\n",
    "    def update(self, metric_name, val):\n",
    "        metric = self.metrics[metric_name]\n",
    "\n",
    "        metric[\"val\"] += val\n",
    "        metric[\"count\"] += 1\n",
    "        metric[\"avg\"] = metric[\"val\"] / metric[\"count\"]\n",
    "\n",
    "    def __str__(self):\n",
    "        return \" | \".join(\n",
    "            [\n",
    "                \"{metric_name}: {avg:.{float_precision}f}\".format(\n",
    "                    metric_name=metric_name, avg=metric[\"avg\"], float_precision=self.float_precision\n",
    "                )\n",
    "                for (metric_name, metric) in self.metrics.items()\n",
    "            ]\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sp1tsqfS2z5Z"
   },
   "source": [
    "## 2.2 Early Stopping\n",
    "Early stopping is a form of regularization used to avoid overfitting on the training dataset. Early stopping keeps track of the validation loss, if the loss stops decreasing for several epochs in a row the training stops. The ```EarlyStopping``` class is used to create an object to keep track of the validation loss. It will save a checkpoint of the model each time the validation loss decrease.  We set the ```patience``` argument to how many epochs we want to wait after the last time the validation loss improved before breaking the training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "Zh7tkIkK13dQ"
   },
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n",
    "        \"\"\"\n",
    "        Source:\n",
    "            https://github.com/Bjarten/early-stopping-pytorch/blob/master/pytorchtools.py\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "                            Default: 7\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
    "                            Default: False\n",
    "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "                            Default: 0\n",
    "            path (str): Path for the checkpoint to be saved to.\n",
    "                            Default: 'checkpoint.pt'\n",
    "            trace_func (function): trace print function.\n",
    "                            Default: print            \n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        self.trace_func = trace_func\n",
    "    def __call__(self, val_loss, model):\n",
    "\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            self.trace_func(f'> early stopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        '''Saves model when validation loss decrease.'''\n",
    "        if self.verbose:\n",
    "            self.trace_func(f'validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uLFtDthc2R8Z"
   },
   "source": [
    "## 2.3 Calculate Accuracy\n",
    "Accuracy is one metric for evaluating classification models. Informally, accuracy is the fraction of predictions our model got right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "KZtARFoQ2hE_"
   },
   "outputs": [],
   "source": [
    "def calculate_accuracy(output, target):\n",
    "    \"Calculates accuracy\"\n",
    "    output = output.data.max(dim=1,keepdim=True)[1]\n",
    "    output = output == 1.0\n",
    "    output = torch.flatten(output)\n",
    "    target = target == 1.0\n",
    "    target = torch.flatten(target)\n",
    "    return torch.true_divide((target == output).sum(dim=0), output.size(0)).item() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NLtlGGP42-mk"
   },
   "source": [
    "## 2.4 Save Model\n",
    "Save the current state of the model alongside with the optimizer and the current epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "aA92OLnc3AVr"
   },
   "outputs": [],
   "source": [
    "def save_model(model, optimizer, epoch, save_file):\n",
    "    print('\\n==> Saving...')\n",
    "    state = {\n",
    "        'model': model.state_dict(),\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "        'epoch': epoch,\n",
    "    }\n",
    "    torch.save(state, save_file)\n",
    "    del state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "htwdrWUS3GQu"
   },
   "source": [
    "## 2.5 Two Crop Transform\n",
    "Creates two crops of the same image which are the result of a stochastic augmentation defined as a transform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "8SaaWs9w3HqS"
   },
   "outputs": [],
   "source": [
    "class TwoCropTransform:\n",
    "    \"\"\"Create two crops of the same image\"\"\"\n",
    "    def __init__(self, transform):\n",
    "        self.transform = transform\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return [self.transform(x), self.transform(x)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "13lsLXFQ2CtG"
   },
   "source": [
    "# 3. Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DrYrVHEv2L_d"
   },
   "source": [
    "## 3.1 Contrastive Framework SimCLR\n",
    "The contrastive framework SimCLR consists of:\n",
    "* Data augmentation module, ```Aug(·)```. For each input sample ```x```, we generate two random augmentations, each of which represents a different view of the data and contrains some subset of the information in the original sample\n",
    "* Encoder Network, ```Enc(·)```, which maps input sample ```x```' to a repesentation vector ```r=Enc(x)```. Both augmented samples are separately input to the same encoder, resulting in a pair of representation vectors. ```r``` is normalized to the unit hypersphere.\n",
    "* Projection Network, ```Proj(·)```, which maps ```r``` to a vector ```z=Proj(r)```. We instantiate as either a multi-layer perceptron with a single hidden layer of size 2048 and output vector of size 128 or just a single linear layer of size 128. We again normalize the output of this network to lie on the unit hypersphere, which enables using an inner product to measure distances in the projection space. As in self-supervised contrastive learning we discard ```Proj(·)``` at the end of contrastive training. As a result, our inference-time models contain exactly the same number of parameters as a cross-entropy model using the same encoder, ```Enc(·)```.\n",
    "* Contrastive loss functions defined for a contrastive prediction task. For the supervised version, see [Supervised Contrastive Learning](https://arxiv.org/pdf/2004.11362.pdf). For the self-supervised version, see [A Simple Framework for Contrastive Learning of Visual Representations](https://arxiv.org/pdf/2002.05709.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "VhCOJQS92eTr"
   },
   "outputs": [],
   "source": [
    "class Encoder(torch.nn.Module):\n",
    "    \"Encoder network\"\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        # L1 (?, 28, 28, 1) -> (?, 28, 28, 32) -> (?, 14, 14, 32)\n",
    "        self.layer1 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.BatchNorm2d(32),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            torch.nn.Dropout(p=0.2)\n",
    "            )\n",
    "        # L2 (?, 14, 14, 32) -> (?, 14, 14, 64) -> (?, 7, 7, 64)\n",
    "        self.layer2 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.BatchNorm2d(64),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            torch.nn.Dropout(p=0.2)\n",
    "            )\n",
    "        # L3 (?, 7, 7, 64) -> (?, 7, 7, 128) -> (?, 4, 4, 128)\n",
    "        self.layer3 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.BatchNorm2d(128),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2, padding=1),\n",
    "            torch.nn.Dropout(p=0.2)\n",
    "            )\n",
    "        self._to_linear = 4 * 4 * 128\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = x.view(x.size(0), -1) # Flatten them for FC\n",
    "        return x\n",
    "    \n",
    "\n",
    "class LinearClassifier(torch.nn.Module):\n",
    "    \"\"\"Linear classifier\"\"\"\n",
    "    def __init__(self):\n",
    "        super(LinearClassifier, self).__init__()\n",
    "        self.fc = torch.nn.Sequential(\n",
    "            torch.nn.Linear(4 * 4 * 128, 10),\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        probs = torch.nn.functional.softmax(x, dim=0)\n",
    "        return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SupCon(nn.Module):\n",
    "    \"\"\"encoder + projection head\"\"\"\n",
    "    def __init__(self, model, head='mlp', feat_dim=128):\n",
    "        super(SupCon, self).__init__()\n",
    "        \n",
    "        self.dim_in = model._to_linear\n",
    "        self.encoder = model\n",
    "        \n",
    "        if head == 'linear':\n",
    "            self.head = nn.Linear(self.dim_in, feat_dim)\n",
    "        elif head == 'mlp':\n",
    "            self.head = nn.Sequential(\n",
    "                nn.Linear(self.dim_in, self.dim_in),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Linear(self.dim_in, feat_dim)\n",
    "            )\n",
    "        else:\n",
    "            raise NotImplementedError('Head not supported: {}'.format(head))\n",
    "\n",
    "    def forward(self, x):\n",
    "        feat = self.encoder(x)\n",
    "        feat = F.normalize(self.head(feat), dim=1)\n",
    "        return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Author: Yonglong Tian (yonglong@mit.edu)\n",
    "Date: May 07, 2020\n",
    "\"\"\"\n",
    "class SupConLoss(nn.Module):\n",
    "    def __init__(self, temperature=0.07, contrast_mode='all',\n",
    "                 base_temperature=0.07):\n",
    "        super(SupConLoss, self).__init__()\n",
    "        self.temperature = temperature\n",
    "        self.contrast_mode = contrast_mode\n",
    "        self.base_temperature = base_temperature\n",
    "\n",
    "    def forward(self, features, labels=None, mask=None):\n",
    "        device = (torch.device('cuda')\n",
    "                  if features.is_cuda\n",
    "                  else torch.device('cpu'))\n",
    "\n",
    "        if len(features.shape) < 3:\n",
    "            raise ValueError('`features` needs to be [bsz, n_views, ...],'\n",
    "                             'at least 3 dimensions are required')\n",
    "        if len(features.shape) > 3:\n",
    "            features = features.view(features.shape[0], features.shape[1], -1)\n",
    "\n",
    "        batch_size = features.shape[0]\n",
    "        if labels is not None and mask is not None:\n",
    "            raise ValueError('Cannot define both `labels` and `mask`')\n",
    "        elif labels is None and mask is None:\n",
    "            mask = torch.eye(batch_size, dtype=torch.float32).to(device)\n",
    "        elif labels is not None:\n",
    "            labels = labels.contiguous().view(-1, 1)\n",
    "            if labels.shape[0] != batch_size:\n",
    "                raise ValueError('Num of labels does not match num of features')\n",
    "            mask = torch.eq(labels, labels.T).float().to(device)\n",
    "        else:\n",
    "            mask = mask.float().to(device)\n",
    "\n",
    "        contrast_count = features.shape[1]\n",
    "        contrast_feature = torch.cat(torch.unbind(features, dim=1), dim=0)\n",
    "        if self.contrast_mode == 'one':\n",
    "            anchor_feature = features[:, 0]\n",
    "            anchor_count = 1\n",
    "        elif self.contrast_mode == 'all':\n",
    "            anchor_feature = contrast_feature\n",
    "            anchor_count = contrast_count\n",
    "        else:\n",
    "            raise ValueError('Unknown mode: {}'.format(self.contrast_mode))\n",
    "\n",
    "        # compute logits\n",
    "        anchor_dot_contrast = torch.div(\n",
    "            torch.matmul(anchor_feature, contrast_feature.T),\n",
    "            self.temperature)\n",
    "        # for numerical stability\n",
    "        logits_max, _ = torch.max(anchor_dot_contrast, dim=1, keepdim=True)\n",
    "        logits = anchor_dot_contrast - logits_max.detach()\n",
    "\n",
    "        # tile mask\n",
    "        mask = mask.repeat(anchor_count, contrast_count)\n",
    "        # mask-out self-contrast cases\n",
    "        logits_mask = torch.scatter(\n",
    "            torch.ones_like(mask),\n",
    "            1,\n",
    "            torch.arange(batch_size * anchor_count).view(-1, 1).to(device),\n",
    "            0\n",
    "        )\n",
    "        mask = mask * logits_mask\n",
    "\n",
    "        # compute log_prob\n",
    "        exp_logits = torch.exp(logits) * logits_mask\n",
    "        log_prob = logits - torch.log(exp_logits.sum(1, keepdim=True))\n",
    "\n",
    "        # compute mean of log-likelihood over positive\n",
    "        mean_log_prob_pos = (mask * log_prob).sum(1) / mask.sum(1)\n",
    "\n",
    "        # loss\n",
    "        loss = - (self.temperature / self.base_temperature) * mean_log_prob_pos\n",
    "        loss = loss.view(anchor_count, batch_size).mean()\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cRtcShmV2WvX"
   },
   "source": [
    "## 3.3 Pre-Training\n",
    "Main training loop of **encoder** and **projection head** for a number of batches over an epoch, as it is defined in [PyTorch](https://pytorch.org/). Note that the loss used in the ```SupConLoss``` defined just for the pre-training. If CUDA is availiable, training will take place in GPU. ```EarlyStopping``` class is used to keep track of loss and accuracy. Returns the loss and accuracy of the epoch.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "VWJL-DyW2j5g"
   },
   "outputs": [],
   "source": [
    "def pretraining(epoch, model, contrastive_loader, optimizer, criterion, method='SimCLR'):\n",
    "    \"Contrastive pre-training over an epoch\"\n",
    "    metric_monitor = MetricMonitor()\n",
    "    model.train()\n",
    "    for batch_idx, (data,labels) in enumerate(contrastive_loader):\n",
    "        data = torch.cat([data[0], data[1]], dim=0)\n",
    "        if torch.cuda.is_available():\n",
    "            data,labels = data.cuda(), labels.cuda()\n",
    "        data, labels = torch.autograd.Variable(data,False), torch.autograd.Variable(labels)\n",
    "        bsz = labels.shape[0]\n",
    "        features = model(data)\n",
    "        f1, f2 = torch.split(features, [bsz, bsz], dim=0)\n",
    "        features = torch.cat([f1.unsqueeze(1), f2.unsqueeze(1)], dim=1)\n",
    "        if method == 'SupCon':\n",
    "            loss = criterion(features, labels)\n",
    "        elif method == 'SimCLR':\n",
    "            loss = criterion(features)\n",
    "        else:\n",
    "            raise ValueError('contrastive method not supported: {}'.format(method))\n",
    "        metric_monitor.update(\"Loss\", loss.item())\n",
    "        metric_monitor.update(\"Learning Rate\", optimizer.param_groups[0]['lr'])\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(\"[Epoch: {epoch:03d}] Contrastive Pre-train | {metric_monitor}\".format(epoch=epoch, metric_monitor=metric_monitor))\n",
    "    return metric_monitor.metrics['Loss']['avg'], metric_monitor.metrics['Learning Rate']['avg']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mTEqEQpS2W_k"
   },
   "source": [
    "## 3.3 Training\n",
    "Main training loop of **classifier** for a number of batches over an epoch, as it is defined in [PyTorch](https://pytorch.org/). Note that model, which is defined as the encoder and the projection head is set in evaluation mode and no training of its wieght happens. If CUDA is availiable, training will take place in GPU. ```EarlyStopping``` class is used to keep track of loss and accuracy. Returns the loss and accuracy of the epoch.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "nHCnAbSV2kj6"
   },
   "outputs": [],
   "source": [
    "def training(epoch, model, classifier, train_loader, optimizer, criterion):\n",
    "    \"Training over an epoch\"\n",
    "    metric_monitor = MetricMonitor()\n",
    "    model.eval()\n",
    "    classifier.train()\n",
    "    for batch_idx, (data,labels) in enumerate(train_loader):\n",
    "        if torch.cuda.is_available():\n",
    "            data,labels = data.cuda(), labels.cuda()\n",
    "        data, labels = torch.autograd.Variable(data,False), torch.autograd.Variable(labels)\n",
    "        with torch.no_grad():\n",
    "            features = model.encoder(data)\n",
    "        output = classifier(features.float())\n",
    "        loss = criterion(output, labels) \n",
    "        accuracy = calculate_accuracy(output, labels)\n",
    "        metric_monitor.update(\"Loss\", loss.item())\n",
    "        metric_monitor.update(\"Accuracy\", accuracy)\n",
    "        data.detach()\n",
    "        labels.detach()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(\"[Epoch: {epoch:03d}] Train      | {metric_monitor}\".format(epoch=epoch, metric_monitor=metric_monitor))\n",
    "    return metric_monitor.metrics['Loss']['avg'], metric_monitor.metrics['Accuracy']['avg']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "abiLjLhf3yQK"
   },
   "source": [
    "## 3.4 Validation\n",
    "Main validation loop of **encoder** and **classifier** for a number of batches over an epoch, as it is defined in [PyTorch](https://pytorch.org/). Projection head is not used for the validation process in SimCLR. If CUDA is availiable, training will take place in GPU. ```EarlyStopping``` class is used to keep track of loss and accuracy. Returns the loss and accuracy of the epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "XF9NIV7T3zrR"
   },
   "outputs": [],
   "source": [
    "def validation(epoch, model, classifier, valid_loader, criterion):\n",
    "    \"Validation over an epoch\"\n",
    "    metric_monitor = MetricMonitor()\n",
    "    model.eval()\n",
    "    classifier.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data,labels) in enumerate(valid_loader):\n",
    "            if torch.cuda.is_available():\n",
    "                data,labels = data.cuda(), labels.cuda()\n",
    "            data, labels = torch.autograd.Variable(data,False), torch.autograd.Variable(labels)\n",
    "            features = model.encoder(data)\n",
    "            output = classifier(features.float())\n",
    "            loss = criterion(output,labels) \n",
    "            accuracy = calculate_accuracy(output, labels)\n",
    "            metric_monitor.update(\"Loss\", loss.item())\n",
    "            metric_monitor.update(\"Accuracy\", accuracy)\n",
    "            data.detach()\n",
    "            labels.detach()\n",
    "    print(\"[Epoch: {epoch:03d}] Validation | {metric_monitor}\".format(epoch=epoch, metric_monitor=metric_monitor))\n",
    "    return metric_monitor.metrics['Loss']['avg'], metric_monitor.metrics['Accuracy']['avg']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5HUFJyf02aYV"
   },
   "source": [
    "# 4. Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "n5XDfwlD2loD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x108fb30a0>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "num_epochs = 5\n",
    "use_early_stopping = True\n",
    "use_scheduler = True\n",
    "head_type = 'mlp' # choose among 'mlp' and 'linear'\n",
    "save_file = os.path.join('./results/', 'model.pth')\n",
    "if not os.path.isdir('./results/'):\n",
    "        os.makedirs('./results/')\n",
    "\n",
    "contrastive_transform = transforms.Compose([\n",
    "                                    transforms.RandomHorizontalFlip(),\n",
    "                                    transforms.RandomResizedCrop(size=28, scale=(0.2, 1.)),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize((0.5,), (0.5,)),\n",
    "                                    ])\n",
    "train_transform = transforms.Compose([\n",
    "                                    transforms.RandomHorizontalFlip(),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize((0.5,), (0.5,)),\n",
    "                                    ])\n",
    "valid_transform = transforms.Compose([\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize((0.5,), (0.5,)),\n",
    "                                    ])\n",
    "\n",
    "# contrastive_set = datasets.MNIST('./data', download=True, train=True, transform=TwoCropTransform(contrastive_transform))\n",
    "# train_set = datasets.MNIST('./data', download=True, train=True, transform=train_transform)\n",
    "# valid_set = datasets.MNIST('./data', download=True, train=False, transform=valid_transform)\n",
    "# these are the datasets, we have to check what is happening with this and then replace the data.\n",
    "contrastive_set = pkl.load(open('./../code/GER_train.pkl', 'rb'))\n",
    "contrastive_set_labels = pkl.load('../code/GER_train_y.pkl')\n",
    "train_set = pkl.load(open('./../code/GER_train.pkl', 'rb'))\n",
    "train_set_labels = pkl.load('../code/GER_train_y.pkl')\n",
    "valid_set = pkl.load(open('./../code/GER_test.pkl', 'rb'))\n",
    "valid_set_labels = pkl.load('../code/GER_test_y.pkl')\n",
    "contrastive_loader = torch.utils.data.DataLoader(contrastive_set, batch_size=64, shuffle=True)\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=64, shuffle=True)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_set, batch_size=64, shuffle=True)\n",
    "# Thinking about loading the test data in the place of validation data.\n",
    "\n",
    "# Part 1\n",
    "encoder = Encoder()\n",
    "model = SupCon(encoder, head=head_type, feat_dim=128)\n",
    "criterion = SupConLoss(temperature=0.07)\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "    criterion = criterion.cuda()   \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, betas=(0.9, 0.999), eps=1e-08, weight_decay=1e-3)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.9)\n",
    "\n",
    "contrastive_loss, contrastive_lr = [], []\n",
    "print(contrastive_loader)\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    print(epoch)\n",
    "    loss, lr = pretraining(epoch, model, contrastive_loader, optimizer, criterion, method='SimCLR')\n",
    "    if use_scheduler:\n",
    "        scheduler.step()\n",
    "    contrastive_loss.append(loss)\n",
    "    contrastive_lr.append(lr)\n",
    "\n",
    "save_model(model, optimizer, num_epochs, save_file)\n",
    "\n",
    "plt.plot(range(1,len(contrastive_lr)+1),contrastive_lr, color='b', label = 'learning rate')\n",
    "plt.legend(), plt.ylabel('loss'), plt.xlabel('epochs'), plt.title('Learning Rate'), plt.show()\n",
    "\n",
    "plt.plot(range(1,len(contrastive_loss)+1),contrastive_loss, color='b', label = 'loss')\n",
    "plt.legend(), plt.ylabel('loss'), plt.xlabel('epochs'), plt.title('Loss'), plt.show()\n",
    "\n",
    "# Part 2\n",
    "model = SupCon(encoder, head=head_type, feat_dim=128)\n",
    "classifier = LinearClassifier()\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "ckpt = torch.load(save_file, map_location='cpu')\n",
    "state_dict = ckpt['model']\n",
    "new_state_dict = {}\n",
    "for k, v in state_dict.items():\n",
    "    k = k.replace(\"module.\", \"\")\n",
    "    new_state_dict[k] = v\n",
    "state_dict = new_state_dict\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "    classifier = classifier.cuda()\n",
    "    criterion = criterion.cuda()\n",
    "\n",
    "train_losses , train_accuracies = [],[]\n",
    "valid_losses , valid_accuracies = [],[]\n",
    "\n",
    "if use_early_stopping:\n",
    "    early_stopping = EarlyStopping(patience=30, verbose=False, delta=1e-4)\n",
    "\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    print(epoch)\n",
    "    train_loss, train_accuracy = training(epoch, model, classifier, train_loader, optimizer, criterion)\n",
    "    valid_loss, valid_accuracy = validation(epoch, model, classifier, valid_loader, criterion)\n",
    "    \n",
    "    if use_scheduler:\n",
    "        scheduler.step()\n",
    "        \n",
    "    train_losses.append(train_loss)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    valid_losses.append(valid_loss)\n",
    "    valid_accuracies.append(valid_accuracy)\n",
    "            \n",
    "    if use_early_stopping: \n",
    "        early_stopping(valid_loss, model)\n",
    "        \n",
    "        if early_stopping.early_stop:\n",
    "            print('Early stopping at epoch', epoch)\n",
    "            #model.load_state_dict(torch.load('checkpoint.pt'))\n",
    "            break\n",
    "plt.plot(range(1,len(train_losses)+1), train_losses, color='b', label = 'training loss')\n",
    "plt.plot(range(1,len(valid_losses)+1), valid_losses, color='r', linestyle='dashed', label = 'validation loss')\n",
    "plt.legend(), plt.ylabel('loss'), plt.xlabel('epochs'), plt.title('Loss'), plt.show()\n",
    "    \n",
    "plt.plot(range(1,len(train_accuracies)+1),train_accuracies, color='b', label = 'training accuracy')\n",
    "plt.plot(range(1,len(valid_accuracies)+1),valid_accuracies, color='r', linestyle='dashed', label = 'validation accuracy')\n",
    "plt.legend(), plt.ylabel('loss'), plt.xlabel('epochs'), plt.title('Accuracy'), plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.04631804, 0.14190991, 0.08418234, ..., 0.3600657 , 0.32142857,\n",
       "        0.5       ],\n",
       "       [0.07397126, 0.0878519 , 0.07133727, ..., 0.19447861, 0.67857143,\n",
       "        0.5       ],\n",
       "       [0.03770867, 0.06151615, 0.02738048, ..., 0.20603255, 0.15909091,\n",
       "        0.16853933],\n",
       "       ...,\n",
       "       [0.10647534, 0.13753633, 0.06430933, ..., 0.37192569, 0.2745098 ,\n",
       "        0.38961039],\n",
       "       [0.04122387, 0.04372108, 0.04135551, ..., 0.08562723, 0.11764706,\n",
       "        0.12987013],\n",
       "       [0.15451053, 0.12892201, 0.11704483, ..., 0.36913921, 0.60784314,\n",
       "        0.48051948]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contrastive_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "MNIST_classification_main_simclr.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
